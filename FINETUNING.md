# Guia de Fine-tuning para Face Recognition

Este documento apresenta um guia completo para realizar fine-tuning do modelo de Face Recognition treinado no VGGFace2 em um novo conjunto de dados.

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [PrÃ©-requisitos](#prÃ©-requisitos)
3. [Estrutura do Dataset](#estrutura-do-dataset)
4. [EstratÃ©gias de Fine-tuning](#estratÃ©gias-de-fine-tuning)
5. [Passo a Passo](#passo-a-passo)
6. [Salvamento de Modelos](#salvamento-de-modelos)
7. [Monitoramento e AvaliaÃ§Ã£o](#monitoramento-e-avaliaÃ§Ã£o)
8. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

O fine-tuning permite adaptar um modelo prÃ©-treinado (treinado no VGGFace2 e validado no LFW) para um novo conjunto de dados especÃ­fico. Este processo Ã© mais eficiente que treinar do zero e geralmente produz melhores resultados com menos dados.

### Quando usar Fine-tuning?

- âœ… VocÃª tem um novo conjunto de dados com classes diferentes do VGGFace2
- âœ… VocÃª tem um conjunto de dados menor (< 100k imagens)
- âœ… VocÃª quer adaptar o modelo para um domÃ­nio especÃ­fico
- âœ… VocÃª quer manter as caracterÃ­sticas aprendidas do modelo original

---

## ğŸ“¦ PrÃ©-requisitos

### 1. Modelo PrÃ©-treinado

VocÃª precisa ter um modelo prÃ©-treinado salvo. O modelo deve ser do tipo `.keras` e conter:
- Backbone ResNet50
- Camada CosFace
- Pesos treinados no VGGFace2

**LocalizaÃ§Ã£o esperada:** O modelo pode estar em qualquer local. Exemplos:
- `experiments/Resnet50_vgg_cropado_CelebA/checkpoints/epoch_XX.keras`
- `models/pretrained_model.keras`

### 2. Novo Dataset

O novo dataset deve estar organizado em uma das seguintes estruturas:

#### OpÃ§Ã£o A: Dataset com divisÃ£o train/val
```
/dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ pessoa_001/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â”œâ”€â”€ img2.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ pessoa_002/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ pessoa_001/
    â”œâ”€â”€ pessoa_002/
    â””â”€â”€ ...
```

#### OpÃ§Ã£o B: Dataset Ãºnico (serÃ¡ dividido automaticamente)
```
/dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
â”œâ”€â”€ pessoa_001/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”œâ”€â”€ img2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ pessoa_002/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

**Requisitos:**
- Imagens devem estar alinhadas e redimensionadas para 112x112 pixels
- Formato: JPG ou PNG
- Cada pasta representa uma classe (pessoa)
- MÃ­nimo recomendado: 10 imagens por classe

### 3. DependÃªncias

Certifique-se de que todas as dependÃªncias estÃ£o instaladas:

```bash
pip install -r requirements.txt
```

---

## ğŸ”§ EstratÃ©gias de Fine-tuning

O script oferece 3 estratÃ©gias diferentes, cada uma adequada para diferentes cenÃ¡rios:

### EstratÃ©gia 1: Full Fine-tuning (Fine-tuning Completo)

**Quando usar:**
- VocÃª tem um dataset grande (> 10k imagens)
- O novo dataset Ã© similar ao VGGFace2
- VocÃª quer mÃ¡xima adaptaÃ§Ã£o ao novo domÃ­nio

**CaracterÃ­sticas:**
- Todas as camadas do backbone sÃ£o treinÃ¡veis
- Todas as camadas da cabeÃ§a sÃ£o treinÃ¡veis
- Learning rate: 10% do learning rate original
- Mais flexÃ­vel, mas requer mais dados

**Comando:**
```bash
python run_finetuning.py \
    --strategy 1 \
    --pretrained_model experiments/Resnet50_vgg_cropado_CelebA/checkpoints/epoch_30.keras \
    --dataset_path /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --output_dir experiments/finetuning_strategy1 \
    --epochs 30 \
    --batch_size 64
```

---

### EstratÃ©gia 2: Partial Fine-tuning (Fine-tuning Parcial)

**Quando usar:**
- VocÃª tem um dataset mÃ©dio (1k - 10k imagens)
- Quer evitar overfitting
- Quer preservar mais caracterÃ­sticas do modelo original

**CaracterÃ­sticas:**
- Apenas as Ãºltimas N camadas do backbone sÃ£o treinÃ¡veis
- Todas as camadas da cabeÃ§a sÃ£o treinÃ¡veis
- Camadas iniciais do backbone permanecem congeladas
- Menos parÃ¢metros treinÃ¡veis = menos risco de overfitting

**ParÃ¢metros:**
- `--num_layers`: NÃºmero de camadas finais a treinar (default: 10)
  - Valores recomendados: 5-20
  - Mais camadas = mais adaptaÃ§Ã£o, mas mais risco de overfitting

**Comando:**
```bash
python run_finetuning.py \
    --strategy 2 \
    --pretrained_model experiments/Resnet50_vgg_cropado_CelebA/checkpoints/epoch_30.keras \
    --dataset_path /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --output_dir experiments/finetuning_strategy2 \
    --epochs 30 \
    --batch_size 64 \
    --num_layers 15
```

---

### EstratÃ©gia 3: Differential LR Fine-tuning (LR Diferenciado)

**Quando usar:**
- VocÃª quer um equilÃ­brio entre adaptaÃ§Ã£o e preservaÃ§Ã£o
- VocÃª tem experiÃªncia com fine-tuning
- VocÃª quer mÃ¡xima performance

**CaracterÃ­sticas:**
- Todas as camadas sÃ£o treinÃ¡veis
- Learning rates diferenciados por profundidade:
  - Camadas profundas: LR muito baixo (preserva features bÃ¡sicas)
  - Camadas mÃ©dias: LR mÃ©dio
  - Camadas superficiais: LR mais alto (adapta features especÃ­ficas)
  - CabeÃ§a: LR mais alto ainda

**Nota:** A implementaÃ§Ã£o atual usa um LR mÃ©dio. Para LR verdadeiramente diferenciado, considere treinar em fases ou usar uma implementaÃ§Ã£o customizada.

**Comando:**
```bash
python run_finetuning.py \
    --strategy 3 \
    --pretrained_model experiments/Resnet50_vgg_cropado_CelebA/checkpoints/epoch_30.keras \
    --dataset_path /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --output_dir experiments/finetuning_strategy3 \
    --epochs 30 \
    --batch_size 64
```

---

## ğŸ“ Passo a Passo

### Passo 1: Preparar o Ambiente

```bash
# Navegar para o diretÃ³rio do projeto
cd /Users/wgalvao/Noleak/Implementacao-Cosface

# Verificar se o modelo prÃ©-treinado existe
ls -lh experiments/Resnet50_vgg_cropado_CelebA/checkpoints/

# Verificar se o dataset estÃ¡ acessÃ­vel
ls -lh /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
```

### Passo 2: Verificar o Dataset

```bash
# Contar nÃºmero de classes
find /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ -type d -mindepth 1 -maxdepth 1 | wc -l

# Verificar estrutura (se tem train/val)
ls /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
```

### Passo 3: Escolher a EstratÃ©gia

Considere:
- **Tamanho do dataset**: Pequeno â†’ EstratÃ©gia 2, Grande â†’ EstratÃ©gia 1
- **Similaridade com VGGFace2**: Similar â†’ EstratÃ©gia 1, Diferente â†’ EstratÃ©gia 2
- **Recursos computacionais**: Limitados â†’ EstratÃ©gia 2, Abundantes â†’ EstratÃ©gia 1

### Passo 4: Executar o Fine-tuning

**Exemplo completo com EstratÃ©gia 1:**

```bash
python run_finetuning.py \
    --strategy 1 \
    --pretrained_model experiments/Resnet50_vgg_cropado_CelebA/checkpoints/epoch_30.keras \
    --dataset_path /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --output_dir experiments/finetuning_strategy1 \
    --epochs 30 \
    --batch_size 64 \
    --learning_rate 0.0005
```

**Exemplo com EstratÃ©gia 2 (recomendado para comeÃ§ar):**

```bash
python run_finetuning.py \
    --strategy 2 \
    --pretrained_model experiments/Resnet50_vgg_cropado_CelebA/checkpoints/epoch_30.keras \
    --dataset_path /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --output_dir experiments/finetuning_strategy2 \
    --epochs 30 \
    --batch_size 64 \
    --num_layers 10
```

### Passo 5: Monitorar o Progresso

Durante o treinamento, vocÃª verÃ¡:
- Progresso por Ã©poca
- Loss e acurÃ¡cia de treino
- Loss e acurÃ¡cia de validaÃ§Ã£o (se disponÃ­vel)
- Learning rate atual

### Passo 6: Verificar Resultados

ApÃ³s o treinamento, verifique:

```bash
# Verificar checkpoints salvos
ls -lh experiments/finetuning_strategy1/checkpoints/

# Verificar logs
head experiments/finetuning_strategy1/logs/finetuning_full_fine-tuning_log.csv

# Verificar figuras geradas
ls -lh experiments/finetuning_strategy1/figures/
```

---

## ğŸ’¾ Salvamento de Modelos

### Estrutura de SaÃ­da

O script cria a seguinte estrutura:

```
experiments/finetuning_strategy1/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ finetuning_full_fine-tuning_epoch_01.keras
â”‚   â”œâ”€â”€ finetuning_full_fine-tuning_epoch_02.keras
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ finetuning_full_fine-tuning_log.csv
â”œâ”€â”€ figures/
â”‚   â””â”€â”€ finetuning_history_full_fine-tuning.png
â””â”€â”€ final_model_full_fine-tuning.keras
```

### Tipos de Modelos Salvos

1. **Checkpoints por Ã‰poca** (`checkpoints/`)
   - Um modelo salvo a cada Ã©poca
   - Ãštil para anÃ¡lise posterior
   - Permite retomar de qualquer Ã©poca

2. **Modelo Final** (`final_model_*.keras`)
   - Modelo da Ãºltima Ã©poca
   - Pronto para uso em produÃ§Ã£o
   - ContÃ©m todos os pesos otimizados

### Carregar Modelo Fine-tuned

```python
import tensorflow as tf
from src.losses.margin_losses import CosFace

# Carregar modelo
model = tf.keras.models.load_model(
    'experiments/finetuning_strategy1/final_model_full_fine-tuning.keras',
    custom_objects={'CosFace': CosFace}
)

# Usar para inferÃªncia
# ... seu cÃ³digo de inferÃªncia ...
```

### Salvar Apenas os Pesos

Se vocÃª quiser salvar apenas os pesos (mais leve):

```python
# ApÃ³s o fine-tuning
model.save_weights('experiments/finetuning_strategy1/final_weights.h5')

# Para carregar depois
model.load_weights('experiments/finetuning_strategy1/final_weights.h5')
```

---

## ğŸ“Š Monitoramento e AvaliaÃ§Ã£o

### Durante o Treinamento

O script gera automaticamente:

1. **Log CSV** (`logs/finetuning_*_log.csv`)
   - ContÃ©m: epoch, loss, accuracy, val_loss, val_accuracy, lr
   - Pode ser aberto no Excel/Pandas para anÃ¡lise

2. **GrÃ¡ficos** (`figures/finetuning_history_*.png`)
   - AcurÃ¡cia de treino e validaÃ§Ã£o
   - Loss de treino e validaÃ§Ã£o
   - Learning rate ao longo do tempo
   - Gap entre treino e validaÃ§Ã£o

### AnÃ¡lise dos Resultados

**Sinais de bom fine-tuning:**
- âœ… Loss diminuindo consistentemente
- âœ… AcurÃ¡cia aumentando
- âœ… Gap pequeno entre treino e validaÃ§Ã£o (< 5%)
- âœ… Sem overfitting (validaÃ§Ã£o acompanha treino)

**Sinais de problemas:**
- âŒ Loss nÃ£o diminui ou aumenta
- âŒ Overfitting (treino muito melhor que validaÃ§Ã£o)
- âŒ AcurÃ¡cia estagnada
- âŒ Loss com NaN

### ValidaÃ§Ã£o no LFW (Opcional)

ApÃ³s o fine-tuning, vocÃª pode validar no LFW:

```bash
python run_validation.py \
    --model_path experiments/finetuning_strategy1/final_model_full_fine-tuning.keras \
    --dataset_path /path/to/validation/dataset \
    --lfw_path /path/to/lfw \
    --lfw_pairs /path/to/lfw_pairs.txt
```

---

## ğŸ” Troubleshooting

### Problema: "Modelo prÃ©-treinado nÃ£o encontrado"

**SoluÃ§Ã£o:**
```bash
# Verificar se o caminho estÃ¡ correto
ls -lh experiments/Resnet50_vgg_cropado_CelebA/checkpoints/

# Usar caminho absoluto
python run_finetuning.py \
    --pretrained_model /caminho/absoluto/para/modelo.keras \
    ...
```

### Problema: "Dataset nÃ£o encontrado"

**SoluÃ§Ã£o:**
```bash
# Verificar permissÃµes
ls -lh /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/

# Verificar estrutura
find /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ -type f | head -10
```

### Problema: "NÃºmero de classes diferente"

**SoluÃ§Ã£o:**
O script ajusta automaticamente o nÃºmero de classes. Se houver erro:
- Verifique se o dataset tem pelo menos 2 classes
- Verifique se as pastas estÃ£o organizadas corretamente

### Problema: "Out of Memory (OOM)"

**SoluÃ§Ãµes:**
1. Reduzir batch size:
   ```bash
   --batch_size 32  # ou 16, ou 8
   ```

2. Usar EstratÃ©gia 2 (menos parÃ¢metros):
   ```bash
   --strategy 2 --num_layers 5
   ```

3. Reduzir tamanho da imagem (modificar config se necessÃ¡rio)

### Problema: "Loss nÃ£o diminui"

**SoluÃ§Ãµes:**
1. Aumentar learning rate:
   ```bash
   --learning_rate 0.001
   ```

2. Verificar se o dataset estÃ¡ correto
3. Verificar se o modelo prÃ©-treinado estÃ¡ carregado corretamente
4. Tentar EstratÃ©gia 1 (mais flexÃ­vel)

### Problema: "Overfitting"

**SoluÃ§Ãµes:**
1. Usar EstratÃ©gia 2:
   ```bash
   --strategy 2 --num_layers 5
   ```

2. Reduzir learning rate:
   ```bash
   --learning_rate 0.0001
   ```

3. Adicionar mais dados de treinamento
4. Usar data augmentation (jÃ¡ incluÃ­do no pipeline)

---

## ğŸ“ˆ RecomendaÃ§Ãµes Finais

### Para Iniciantes

1. Comece com **EstratÃ©gia 2** (`--strategy 2 --num_layers 10`)
2. Use `--epochs 20` para testes iniciais
3. Monitore os grÃ¡ficos gerados
4. Ajuste `--num_layers` baseado nos resultados

### Para Experientes

1. Experimente todas as 3 estratÃ©gias
2. Compare resultados usando os logs CSV
3. Ajuste learning rates baseado no dataset
4. Considere treinar em mÃºltiplas fases

### Boas PrÃ¡ticas

- âœ… Sempre valide em um conjunto de teste separado
- âœ… Salve checkpoints frequentes
- âœ… Monitore overfitting
- âœ… Documente os parÃ¢metros usados
- âœ… Compare diferentes estratÃ©gias no mesmo dataset

---

## ğŸ“š ReferÃªncias

- [CosFace Paper](https://arxiv.org/abs/1801.09414)
- [Transfer Learning Guide](https://www.tensorflow.org/guide/keras/transfer_learning)
- [Fine-tuning Best Practices](https://cs231n.github.io/transfer-learning/)

---

## ğŸ¤ Suporte

Para problemas ou dÃºvidas:
1. Verifique os logs em `experiments/finetuning_*/logs/`
2. Verifique os grÃ¡ficos em `experiments/finetuning_*/figures/`
3. Consulte a seÃ§Ã£o de Troubleshooting acima

---

**Ãšltima atualizaÃ§Ã£o:** 2024

