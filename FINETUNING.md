# Guia de Fine-tuning para Face Recognition

Este documento apresenta um guia completo para realizar fine-tuning do modelo de Face Recognition treinado no VGGFace2 em um novo conjunto de dados.

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [PrÃ©-requisitos](#prÃ©-requisitos)
3. [Estrutura do Dataset](#estrutura-do-dataset)
4. [RetinaFace na ValidaÃ§Ã£o](#retinaface-na-validaÃ§Ã£o)
5. [EstratÃ©gias de Fine-tuning](#estratÃ©gias-de-fine-tuning)
6. [Passo a Passo](#passo-a-passo)
7. [Salvamento de Modelos](#salvamento-de-modelos)
8. [Monitoramento e AvaliaÃ§Ã£o](#monitoramento-e-avaliaÃ§Ã£o)
9. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

O fine-tuning permite adaptar um modelo prÃ©-treinado (treinado no VGGFace2 e validado no LFW) para um novo conjunto de dados especÃ­fico. Este processo Ã© mais eficiente que treinar do zero e geralmente produz melhores resultados com menos dados.

### Quando usar Fine-tuning?

- âœ… VocÃª tem um novo conjunto de dados com classes diferentes do VGGFace2
- âœ… VocÃª tem um conjunto de dados menor (< 100k imagens)
- âœ… VocÃª quer adaptar o modelo para um domÃ­nio especÃ­fico
- âœ… VocÃª quer manter as caracterÃ­sticas aprendidas do modelo original

---

## ğŸ“¦ PrÃ©-requisitos

### 1. Modelo PrÃ©-treinado

VocÃª precisa ter um modelo prÃ©-treinado salvo. O modelo deve ser do tipo `.keras` e conter:
- Backbone ResNet50
- Camada CosFace
- Pesos treinados no VGGFace2

**LocalizaÃ§Ã£o esperada:** O modelo pode estar em qualquer local. Exemplos:
- `experiments/Resnet50_vgg_cropado_CelebA/checkpoints/epoch_XX.keras`
- `models/pretrained_model.keras`

### 2. Novo Dataset

O novo dataset deve estar organizado em uma das seguintes estruturas:

#### OpÃ§Ã£o A: Dataset com divisÃ£o train/val
```
/dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ pessoa_001/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â”œâ”€â”€ img2.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ pessoa_002/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ pessoa_001/
    â”œâ”€â”€ pessoa_002/
    â””â”€â”€ ...
```

#### OpÃ§Ã£o B: Dataset Ãºnico (serÃ¡ dividido automaticamente)
```
/dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
â”œâ”€â”€ pessoa_001/
â”‚   â”œâ”€â”€ img1.jpg
```markdown
# Guia prÃ¡tico de Fine-tuning â€” Cosface

Este documento traz instruÃ§Ãµes concisas e prontas para executar fine-tuning de modelos prÃ©-treinados, incluindo padrÃµes de entrada, estratÃ©gias recomendadas, flags importantes e onde os artefatos sÃ£o salvos.

## RÃ¡pido: prÃ©-requisitos

- Modelo prÃ©-treinado em formato `.keras` (ex.: `experiments/.../epoch_XX.keras`)
- Dataset organizado por pastas (cada pasta = 1 classe) ou com `train/` e `val/` separados
- DependÃªncias: `pip install -r requirements.txt`

RecomendaÃ§Ã£o: imagens alinhadas em 112x112 (como usado no pipeline). MÃ­nimo sugerido: ~10 imagens/por classe.

## Comando essencial

Exemplo genÃ©rico:

```bash
python run_finetuning.py \
  --strategy 2 \
  --pretrained_model /caminho/para/pretrained.keras \
  --dataset_path /caminho/para/dataset \
  --output_dir experiments/finetuning_experiment \
  --epochs 30 \
  --batch_size 64
```

Flags Ãºteis:
- `--strategy`: 1 (full), 2 (partial), 3 (differential LR)
- `--num_layers`: (para strategy 2) nÃºmero de camadas finais a descongelar
- `--use_retinaface`: habilita filtragem por detecÃ§Ã£o de rosto na validaÃ§Ã£o
- `--learning_rate`, `--batch_size`, `--epochs`, `--output_dir`

## EstratÃ©gias (resumo)

- Strategy 1 â€” Full: descongela todo o backbone; use com datasets grandes.
- Strategy 2 â€” Partial: descongela apenas Ãºltimas N camadas; indicado para datasets mÃ©dios/pequenos.
- Strategy 3 â€” Differential LR: todas camadas treinÃ¡veis com polÃ­ticas de LR (usar com cuidado).

RecomendaÃ§Ãµes iniciais: comeÃ§ar com `strategy 2` e `--num_layers 10`, `--epochs 20-30`, `--batch_size 32/64`.

## RetinaFace na validaÃ§Ã£o

OpÃ§Ã£o: `--use_retinaface` â€” aplica detecÃ§Ã£o de faces apenas na fase de validaÃ§Ã£o para excluir imagens sem rosto detectado.

Comportamento:
- Se habilitado, imagens sem detecÃ§Ã£o sÃ£o excluÃ­das da validaÃ§Ã£o. Ãštil quando o dataset contÃ©m ruÃ­do ou imagens sem rosto.
- Se desabilitado, validaÃ§Ã£o usa todas as amostras.

Exemplo habilitando RetinaFace:

```bash
python run_finetuning.py --strategy 1 --pretrained_model /caminho/model.keras --dataset_path /dados --output_dir experiments/fin1 --use_retinaface
```

## SaÃ­da esperada (por `--output_dir`)

Estrutura tÃ­pica criada pelo script:

```
experiments/<nome_experiment>/
â”œâ”€â”€ checkpoints/            # modelos por Ã©poca (epoch_01.keras ...)
â”œâ”€â”€ logs/                   # CSV/JSON com histÃ³rico de treino/val
â”œâ”€â”€ figures/                # PNGs com graphs (loss/acc)
â””â”€â”€ final_model*.keras      # modelo final salvo
```

Use os arquivos em `checkpoints/` para retomar treinos ou para anÃ¡lises histÃ³ricas.

## Como retomar/continuar de um checkpoint

Se quiser retomar, passe o checkpoint como `--pretrained_model` e ajuste hiperparÃ¢metros.

Exemplo:

```bash
python run_finetuning.py --strategy 2 --pretrained_model experiments/finetuning_experiment/checkpoints/epoch_05.keras --dataset_path /dados --output_dir experiments/finetuning_resume --epochs 20
```

## Carregando modelo com objetos customizados

Se o modelo usar perdas/objetos customizados (ex.: CosFace), carregue com `custom_objects` no Keras:

```python
import tensorflow as tf
from src.losses.margin_losses import CosFace

model = tf.keras.models.load_model('experiments/finetuning_experiment/final_model.keras', custom_objects={'CosFace': CosFace}, compile=False)
```

## Troubleshooting rÃ¡pido

- OOM: reduzir `--batch_size`, usar strategy 2 ou reduzir resoluÃ§Ã£o.
- Perda nÃ£o diminui: verificar loading do modelo prÃ©-treinado, aumentar LR ou revisar dados.
- Muitas amostras excluÃ­das pelo RetinaFace: revisar qualidade/align das imagens.

## Monitoramento

- Ver logs em: `experiments/<nome>/logs/` (CSV) â€” abrir com Pandas/Excel para anÃ¡lise.
- Ver plots em: `experiments/<nome>/figures/`.

---

Se quiser, eu deixo esse guia mais detalhado com exemplos de `config/face_recognition_config.py` e um snippet para gerar relatÃ³rios automÃ¡ticos (CSV â†’ PDF) â€” diga qual formato prefere.

```
- ğŸ’¡ **RecomendaÃ§Ã£o**: Use `--use_retinaface` quando o dataset pode conter imagens sem rosto ou de baixa qualidade


